# ğŸ­ MaskGuard - Real-Time Mask Detection System

<div align="center">

A modern, AI-powered face mask detection web application with mobile support. Works on **phones, tablets, and desktops**!

**Developed by Aina** ğŸš€

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0+-green.svg)](https://flask.palletsprojects.com/)
[![YOLO](https://img.shields.io/badge/YOLO-v11-red.svg)](https://docs.ultralytics.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

[About](#-about) â€¢ [Features](#-features) â€¢ [Showcase](#-system-showcase) â€¢ [Quick Start](#-quick-start-local) â€¢ [Deployment](#-deploy-online) â€¢ [How It Works](#-how-it-works) â€¢ [Dataset](#-dataset) â€¢ [Acknowledgments](#-acknowledgments)

</div>

---

## ğŸ“– About

MaskGuard is an intelligent real-time face mask detection system built with Flask, YOLO11, and modern web technologies. The system uses advanced object detection and tracking to monitor mask compliance in real-time, making it perfect for offices, schools, retail stores, healthcare facilities, and public spaces.

**Key Highlights:**
- ğŸ¤– Powered by **Ultralytics YOLO11** pretrained models
- ğŸ“Š Trained on a custom, high-quality dataset from **Kaggle**
- â˜ï¸ Deployable on **Back4App** with automatic HTTPS
- ğŸ¯ Three-class detection: With Mask, Without Mask, Incorrect Mask
- ğŸ”„ Smart tracking with unique IDs (no duplicate counting)

---

## âœ¨ Features

- ğŸ¥ **Real-time Detection** - Instant mask compliance monitoring
- ğŸ“± **Mobile & Desktop** - Works on any device with a camera
- ğŸ”„ **Object Tracking** - Unique IDs for each person (no duplicate counting!)
- ğŸ”Š **Audio Alerts** - Sound + speech warnings for violations
- ğŸ“Š **Live Statistics** - Track compliance in real-time
- ğŸ¨ **Beautiful UI** - Modern, responsive design
- ğŸ”´ **Visual Alerts** - Color-coded bounding boxes (Green = safe, Red = alert)
- âš ï¸ **Environment Warning** - Special alert when >2 people are non-compliant
- ğŸ“· **Camera Switching** - Front/back camera on mobile devices

---

## ğŸ“¸ System Showcase

<div align="center">

### âœ… Mask Worn Correctly
![Mask Worn](md%20imgs/System%20snap(Mask%20Worn).png)

### âŒ Mask Not Worn
![Mask Not Worn](md%20imgs/System%20snap(Mask%20No%20Worn).png)

### âš ï¸ Mask Worn Incorrectly
![Mask Worn Incorrectly](md%20imgs/System%20snap(Mask%20Worn%20Incorectly).png)

</div>

---

## ğŸš€ Quick Start (Local)

### Option 1: Python (Recommended for Development)

**1. Install Dependencies**
```bash
pip install -r requirements.txt
```

**2. Run the App**
```bash
python app.py
```

**3. Open Browser**
```
http://localhost:5000
```

**4. Allow Camera Permissions**
Click "Allow" when browser asks for camera access

### Option 2: Docker (Recommended for Deployment)

**1. Build the Docker Image**
```bash
docker build -t maskguard .
```

**2. Run the Container**
```bash
docker run -p 5000:5000 maskguard
```

**3. Access the App**
```
http://localhost:5000
```

See [`docker-commands.md`](docker-commands.md) for more Docker commands and options.

---

## ğŸŒ Deploy Online

### â­ Recommended: Back4App (Free Tier Available!)

**Professional cloud deployment with zero configuration**

[Back4App](https://www.back4app.com/) is our recommended deployment platform for MaskGuard. It offers:

- âœ… **Free Tier** - Get started at no cost
- âœ… **Automatic HTTPS** - Secure camera access built-in
- âœ… **Easy Deploy** - Connect your GitHub repo and deploy
- âœ… **Scalable** - Handles traffic spikes effortlessly
- âœ… **Global CDN** - Fast performance worldwide

**Quick Deploy Steps:**
1. Sign up for a free [Back4App](https://www.back4app.com/) account
2. Create a new app and connect your GitHub repository
3. Back4App automatically detects Flask and deploys
4. Your app is live with HTTPS! ğŸš€

For detailed step-by-step instructions, see [`BACK4APP_DEPLOYMENT.md`](BACK4APP_DEPLOYMENT.md)

### Alternative Platforms

The app is also compatible with other Flask hosting platforms like Heroku, Railway, Render, or any cloud platform that supports Python/Flask applications.

---

## ğŸ“± How It Works

### Client-Side Camera (JavaScript + WebRTC)
1. Browser requests camera access via WebRTC API
2. JavaScript captures video frames at 10 FPS
3. Frames are encoded to base64 and sent to server via POST request
4. Annotated frames returned and displayed in real-time

### Server-Side Processing (Flask + YOLO)
1. Flask receives base64-encoded frames at `/process_frame` endpoint
2. YOLO model performs object detection and tracking with unique IDs
3. Each person is assigned a persistent track ID
4. Custom bounding boxes drawn with color-coding:
   - **Green** = Wearing mask correctly
   - **Red** = No mask or incorrect mask (triggers alert)
5. Statistics updated (each person counted only once)
6. Annotated frame returned to client

### Detection Classes
- âœ… **With Mask** - Wearing correctly (Green box, no alert)
- âŒ **Without Mask** - Not wearing (Red box + Alert sound)
- âš ï¸ **Incorrect Mask** - Wearing improperly (Red box + Alert sound)

### Smart Tracking
- Each person gets a **unique track ID** that persists across frames
- People are counted only **once** when first detected
- If someone puts on a mask, their status updates without duplicate counting
- Environment alert triggered when >2 people are non-compliant

---

## ğŸ”Œ API Endpoints

The Flask backend provides several API endpoints:

### `GET /`
Main page - serves the web interface

### `POST /process_frame`
Process a single frame from client camera
- **Input**: JSON with base64-encoded image
- **Output**: Annotated image and alert data

### `GET /video_feed`
Server-side camera stream (for local deployment with webcam)
- **Output**: MJPEG stream with real-time detection

### `GET /statistics`
Get current detection statistics
- **Output**: JSON with counts, percentages, and history

### `POST /reset_statistics`
Reset all statistics and tracking data
- **Output**: Success confirmation

### `POST /toggle_detection`
Pause/resume detection
- **Output**: Current pause state

### `GET /health`
Health check endpoint
- **Output**: Server status and model load status

---

## ğŸ® Usage Guide

### Desktop
1. Visit the app URL
2. Allow camera access
3. See real-time detection!

### Mobile
1. Visit the app URL on your phone
2. Allow camera access
3. Use "Switch Camera" button to toggle front/back
4. Works just like desktop!

### Controls
- **Pause/Resume** - Stop/start detection
- **Switch Camera** - Toggle between cameras (mobile)
- **Reset Statistics** - Clear all counts

---

## ğŸ“Š Statistics

### What's Tracked:
- **Total Detections** - Unique people detected
- **With Mask** - People wearing masks correctly
- **Without Mask** - People not wearing masks
- **Incorrect Mask** - People wearing masks improperly
- **Safety Percentage** - Overall compliance rate

### Unique Counting:
Each person gets a **unique ID** and is counted only **once**. If they leave and return, they won't be counted again!

---

## ğŸ”Š Alert System

### Individual Alerts
- Sound plays **once** when someone without proper mask is detected
- Red bounding box with "ALERT" label
- Continues until they put mask on correctly

### Environment Unsafe (>2 people)
- Continuous beeping sound
- Voice alert: "Environment not safe"
- Large warning banner on screen
- Repeats until situation improves

---

## ğŸ› ï¸ Tech Stack

- **Backend**: Flask
- **AI Model**: Ultralytics YOLO (ONNX format)
- **Computer Vision**: OpenCV
- **Frontend**: HTML5, CSS3, JavaScript
- **Camera**: Browser WebRTC API
- **Audio**: Web Audio API + Speech Synthesis API

---

## ğŸ“‚ Project Structure

```
mask2.0/
â”œâ”€â”€ app.py                  # Main Flask application
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best.onnx          # YOLO model (ONNX format)
â”‚   â”œâ”€â”€ best.pt            # YOLO model (PyTorch format)
â”‚   â””â”€â”€ last.pt            # Last checkpoint
â”œâ”€â”€ train/                  # Training results
â”‚   â”œâ”€â”€ weights/           # Model weights
â”‚   â”‚   â”œâ”€â”€ best.pt
â”‚   â”‚   â”œâ”€â”€ best.onnx
â”‚   â”‚   â””â”€â”€ last.pt
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ confusion_matrix_normalized.png
â”‚   â”œâ”€â”€ results.png        # Training metrics graphs
â”‚   â”œâ”€â”€ results.csv        # Training metrics data
â”‚   â”œâ”€â”€ BoxP_curve.png     # Precision curve
â”‚   â”œâ”€â”€ BoxR_curve.png     # Recall curve
â”‚   â”œâ”€â”€ BoxPR_curve.png    # Precision-Recall curve
â”‚   â”œâ”€â”€ BoxF1_curve.png    # F1-Score curve
â”‚   â”œâ”€â”€ train_batch*.jpg   # Training batch samples
â”‚   â”œâ”€â”€ val_batch*.jpg     # Validation batch predictions/labels
â”‚   â”œâ”€â”€ labels.jpg         # Label distribution
â”‚   â””â”€â”€ args.yaml          # Training arguments
â”œâ”€â”€ val/                    # Validation results
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ confusion_matrix_normalized.png
â”‚   â”œâ”€â”€ BoxP_curve.png     # Precision curve
â”‚   â”œâ”€â”€ BoxR_curve.png     # Recall curve
â”‚   â”œâ”€â”€ BoxPR_curve.png    # Precision-Recall curve
â”‚   â”œâ”€â”€ BoxF1_curve.png    # F1-Score curve
â”‚   â””â”€â”€ val_batch*.jpg     # Validation predictions/labels
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css      # Styling
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ app.js         # Main JavaScript
â”‚   â”‚   â””â”€â”€ camera.js      # Camera handler
â”‚   â””â”€â”€ sounds/
â”‚       â””â”€â”€ beep-warning-6387.mp3
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Main page
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ BACK4APP_DEPLOYMENT.md  # Back4App deployment guide
â”œâ”€â”€ QUICKSTART.md           # Quick start guide
â”œâ”€â”€ docker-commands.md      # Docker commands reference
â””â”€â”€ README.md              # This file
```

---

## ğŸ¯ Use Cases

- ğŸ¢ **Office Buildings** - Monitor mask compliance
- ğŸ« **Schools** - Ensure student safety
- ğŸª **Retail Stores** - Track customer compliance
- ğŸ¥ **Healthcare** - Patient and visitor monitoring
- ğŸ­ **Events** - Large gathering safety
- ğŸ“š **Research** - COVID-19 compliance studies

---

## ğŸ”§ Troubleshooting

### Camera Not Working
- **Browser**: Check camera permissions in browser settings
- **Multiple Apps**: Close other apps using camera
- **HTTPS**: Camera requires HTTPS (works automatically when deployed)

### Slow Performance
- **Connection**: Check internet speed
- **Device**: Try on a more powerful device
- **Browser**: Use Chrome/Edge for best performance

### No Detections
- **Lighting**: Ensure good lighting
- **Distance**: Face should be visible and clear
- **Model**: Verify model file exists at `models/best.onnx`

---

## ğŸ“¦ Requirements

- Python 3.8+
- Webcam/Camera
- Modern browser (Chrome, Firefox, Safari, Edge)
- YOLO model trained on mask detection

---

## ğŸŒ Browser Compatibility

| Browser | Desktop | Mobile |
|---------|---------|--------|
| Chrome  | âœ… | âœ… |
| Safari  | âœ… | âœ… |
| Firefox | âœ… | âœ… |
| Edge    | âœ… | âœ… |

---

## ğŸ“ Model Training

This project includes training and validation results in the `train/` and `val/` folders.

### Training Results (`train/`)
The `train/` folder contains comprehensive training outputs:
- **Confusion Matrices** - Both raw and normalized versions showing classification performance
- **Performance Curves** - Precision, Recall, PR, and F1-Score curves
- **Training Metrics** - `results.png` visualizes training progress, `results.csv` contains raw data
- **Sample Batches** - Training and validation batch images with predictions
- **Model Weights** - Best and last checkpoints in both PyTorch (.pt) and ONNX formats
- **Configuration** - `args.yaml` contains all training hyperparameters

### Validation Results (`val/`)
The `val/` folder contains validation-specific outputs:
- **Confusion Matrices** - Performance on validation set
- **Performance Curves** - Validation metrics curves
- **Validation Batches** - Predictions vs ground truth comparisons

### Train Your Own Model
Want to train a custom model? Use:
- Ultralytics YOLOv8 or YOLOv11
- Dataset with three classes: `with_mask`, `without_mask`, `incorrect_mask`
- Export to ONNX format for deployment
- Replace `models/best.onnx` with your trained model

Example training command:
```python
from ultralytics import YOLO

# Train the model
model = YOLO('yolov8n.pt')  # or yolov11n.pt
results = model.train(
    data='your_dataset.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    name='mask_detection'
)

# Export to ONNX
model.export(format='onnx')
```

---

## ğŸ“Š Dataset

This project uses a custom mask detection dataset prepared and cleaned by **Sein Muwana**.

### Dataset Information
- **Name**: Best Mask Detection Dataset
- **Classes**: 3 (with_mask, without_mask, incorrect_mask)
- **Platform**: Kaggle
- **Link**: [Download Dataset on Kaggle](https://www.kaggle.com/datasets/muwanasein/bestset)

The dataset has been carefully curated and annotated to ensure high-quality training data for mask detection models. It includes diverse scenarios with various lighting conditions, angles, and mask types.

### Dataset Statistics
- **Training Images**: Comprehensive collection covering all three classes
- **Validation Images**: Balanced validation set for model evaluation
- **Annotations**: High-quality bounding box annotations
- **Format**: YOLO format (ready to use)

---

## ğŸ¨ Customization

### Change Detection Confidence
In `app.py`, modify the confidence threshold (default is 0.5):
```python
results = model.track(frame, conf=0.5, iou=0.7, persist=True, verbose=False)
# Change conf=0.5 to your desired value (higher = stricter, lower = more detections)
```

### Change FPS
In `static/js/camera.js`, adjust frame processing rate:
```javascript
this.fps = 10;  // Frames per second (default: 10)
```

### Change Alert Threshold
In `app.py`, modify the environment unsafe threshold (default is >2 people):
```python
'environment_unsafe': unsafe_count > 2  # Change 2 to your threshold
```

### Change IOU Threshold
In `app.py`, adjust tracking sensitivity:
```python
results = model.track(frame, conf=0.5, iou=0.7, persist=True, verbose=False)
# Change iou=0.7 to control object tracking overlap threshold
```

---

## ğŸ¤ Contributing

Feel free to fork and improve! Some ideas:
- [ ] Add database for statistics
- [ ] Multi-language support
- [ ] Dark mode theme
- [ ] Export statistics to CSV
- [ ] Email alerts
- [ ] Integration with access control systems

---

## ğŸ“„ License

This project is for educational and safety purposes.

---

## ğŸ‘¨â€ğŸ’» Developer

**Developed by Aina**

- AI-powered mask detection
- Real-time object tracking
- Mobile-first design
- Production-ready code

---

## ğŸ™ Acknowledgments

This project wouldn't be possible without the contributions and support from amazing teams and individuals:

<div align="center">

### ğŸ¤– AI & Model

<table>
<tr>
<td align="center" width="50%">
<img src="md%20imgs/thanks%20ultralytics.svg" width="120" style="border-radius: 50%;" alt="Ultralytics"/><br />
<b><a href="https://docs.ultralytics.com/">Ultralytics Team</a></b><br/>
<sub>For their outstanding YOLO models and the Ultralytics framework that powers our detection system. Their pretrained models and comprehensive documentation made this project possible.</sub>
</td>
<td align="center" width="50%">
<img src="md%20imgs/thanks%20sein-pr.png" width="120" style="border-radius: 50%;" alt="Sein Muwana"/><br />
<b><a href="https://github.com/sein-pr">Sein Muwana</a></b><br/>
<sub>For meticulously preparing, cleaning, and annotating the mask detection dataset available on <a href="https://www.kaggle.com/datasets/muwanasein/bestset">Kaggle</a>. The quality of this dataset was crucial for model training.</sub>
</td>
</tr>
</table>

### â˜ï¸ Infrastructure & Resources

- **[Back4App](https://www.back4app.com/)** - For providing an excellent cloud deployment platform with seamless Flask integration and automatic HTTPS support, making the app accessible worldwide.

- **[Kaggle](https://www.kaggle.com/)** - For providing free GPU resources through Kaggle Notebooks and KaggleHub, enabling us to train our model efficiently without expensive hardware. Their platform democratizes AI development.

### ğŸ› ï¸ Technologies

- **[Flask](https://flask.palletsprojects.com/)** - Web framework powering the backend
- **[OpenCV](https://opencv.org/)** - Computer vision library for image processing
- **[WebRTC](https://webrtc.org/)** - Browser camera API for real-time video capture

</div>

---

## â­ Show Your Support

If you find this project useful, please consider:
- â­ Starring the repository
- ğŸ› Reporting bugs
- ğŸ’¡ Suggesting features
- ğŸ”— Sharing with others

---

**Stay Safe! Wear Your Mask! ğŸ˜·**

